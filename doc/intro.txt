/*! \mainpage The [De]compressor
 *
 * \section intro_sec Introduccion
 *
 * Este programa es utiliza diferentes algoritmos de compresion clasicos para comprimir ficheros de texto en formato '.txt' e imagenes en formato '.ppm'. Para llevar a cabo esta tarea se utilizan los algoritmos de compresion LZ-78, LZ-W y LZ-SS para los ficheros de texto y el algoritmo JPEG para las imagenes.
 *
 * \section detail_sec Los algoritmos en detalle

 * \subsection LZ78 Algoritmo LZ-78
 * El algoritmo LZ78 es un algoritmo basado en repeticiones. En mi caso ha sido implementado a nivel de byte, por lo tanto
 * las repeticiones se corresponden con repeticiones de cadenas de bytes puros, tal y como estan almacenados en memoria
 * para el archivo a comprimir en cuestion.<br>
 *
 * La compresion es sencilla. Consiste en guardar pares de indice y byte. Donde el el indice indica la posicion en el
 * diccionario del antecesor del byte en una cadena de bytes. Cuando el indice es un 0, significa que no hay antecesor.<br>
 *
 * El proceso se inicia leyendo byte a byte el fichero a comprimir. Cada vez que nos encontramos con un byte nunca visto
 * antes, lo almacenamos en un diccionario con una referencia igual al numero cero. De este modo indicamos
 * que este byte no tiene antecesor, y por lo tanto es el inicio de una cadena.<br>
 *
 * En el caso de leer un byte ya visto antes, la cadena actual se debe interpretar como una pareja indice byte, donde el byte
 * es el ultimo leido, y el indice es la posicion de la anterior byte en el diccionario. De este modo, nosotros solo
 * almacenamos parejas de indices y bytes, donde cada byte es el ultimo de la cadena que forma y el indice 'apunta' a su
 * antecesor o nadie (= 0) si este no tiene antecesor y es el primero de su cadena.<br>
 *
 * Dada una cadena de bytes, si el prefijo completo de la cadena ya esta presente en el diccionario, solo necesitamos una
 * entrada para dicha cadena donde: el indice indica la posicion en el diccionario que representa el prefijo y el byte es
 * el que debemos concatenar a dicho prefijo par formar esta cadena.<br>
 *
 * Algoritmicamente tenemos que ir consultando al diccionario si la cadena que consideramos en cada iteracion esta "presente".
 * Si existe un entrada que hace referencia a una cadena A: consideraremos una nueva cadena A' que resulta de concatenar A
 * con el siguiente byte leido. Repetiriamos este proceso hasta que la cadena que consultamos no este presente y entonces,
 * simplemente debemos anadir el indice referente a la subcadena prefijo, y el ultimo byte leido. Cabe remarcar que las primeras
 * iteraciones de este algoritmo son ceros, debido a que el diccionario esta inicialmente vacio.<br>
 *
 * Para descomprimir la informacion, bastaria con leer el diccionario desde el principio hasta el final (en orden). Recursivamente,
 * pensamos en una cadena que se va formando desde la cola hasta el inicio. Mientras el indice de las entradas leidas sea
 * diferente de cero, vamos anadiendo los bytes de estas entradas a nuestra cadena temporal y viajando a la posicion marcada por el
 * indice de los pares leidos. Eventualmente llegaremos a un par con indice = 0, donde deberemos finalizar la formacion de
 * la cadena con el byte de esa entrada y escribir la palabra formada como texto original.<br>
 *
 *
 * \subsection LZSS Algoritmo LZ-SS
 *
 * El algoritmo LZSS es un algoritmo de compresión sin perdida. El
 * algoritmo busca coincidencias para cada carácter del texto a comprimir
 * en los carácteres anteriores, y guarda el desplazamiento hasta la
 * posición en la que empieza la coincidencia, y el numero de carácteres
 * seguidos que coinciden.
 *
 * COMPRESIÓN:
 * Leemos byte a byte el fichero txt que se debe comprimir y lo ponemos en
 * HashMap para acceder de manera eficiente a cada elemento. (coste de acceso
 * logn). Seguidamente lo que haremos es iterar para cada elemento del Hashmap
 * mencionado y añadiremos cada elemento en otro HashMap llamado searchB que
 * será nuestro searchBuffer, en el que buscaremos coincidencias. Por cada
 * elemento en el que iteramos del primer Hashmap, buscaremos en las 4095
 * posiciones anteriores a la ultima posicion del searchB, y en caso que
 * encontremos coincidencia de al menos 3 elementos seguidos, guardaremos
 * en una cola de chars (16bit), 12bits para representar el offset (posicion
 * de la coincidencia) y 4 bits para expresar el desplazamiento (por tanto
 * puede haber hasta 18 carácteres seguidos que coincidan, si cogemos
 * desplazamiento 0 como una coincidencia de 3 elementos, el mínimo). Los
 * elementos con los que no encontremos coincidencias los guardaremos en otra
 * cola de bytes. Paralelamente, guardaremos valor true en un array de bools si
 * hemos encontrado coincidencia para el elemento que iteramos, y false en caso
 * contrario. Escribimos en la salida los booleanos en forma de bits agrupados
 * de 8 en 8 en bytes, seguidamente los bytes correspondientes a los carácteres
 * sin coincidencia y finalmente los chars codificados para representar las
 * coincidencias.
 *
 * DESCOMPRESIÓN:
 * Leemos byte a byte el fichero txt comprimido, y ponemos en 3 colas distintas
 * los valores booleanos, los bytes que representan las no coincidencias y los
 * chars que representan las coincidencias. Seguidamente iteraremos para cada
 * elemento de la cola de booleanos. Si nos encontramos con un false, querrá
 * decir que en esa posición hay un elemento que no coincide y por tanto
 * escribiremos en un array de bytes (representando el resultado) el byte
 * correspondiente al primer elemento de la cola de no coincidencias. En caso
 * que nos encontremos un valor true, querrá decir que en esa posición hay una
 * coincidencia, así que descodificaremos el offset y desplazamiento y añadiremos
 * al resultado los elementos que coinciden. Para la salida, escribimos el array de
 * bytes de resultado byte a byte.
 *
 * \subsection LZW Algoritmo LZ-W
 * LZW es un algoritmo de compresión basado en diccionarios. El algoritmo
 * reemplaza cadenas de caracteres por códigos que representan la posición
 * de esta cadena dentro del diccionario. La comprensión se realiza cuando
 * una cadena con muchos caracteres se se reemplaza por un código que ocupa
 * mucho menos espacio que esa cadena. Tanto la compresión como la descompresión
 * empieza con un alfabeto básico. Por lo tanto es imprescindible que el
 * alfabeto en el proceso de compresión y el de la descompresión sean idénticos.<br>
 *
 * Compresión:
 * Como se ha mencionado antes el algoritmo empieza con un diccionario básico
 * compuesto por todos los caracteres del alfabeto con que se trabaja y
 * lee todos los caracteres de la entrada, uno por uno. Ademas, utiliza un
 * contenedor para crear la nueva palabra que no está en el diccionario.
 * Cuando la encuentra, la añade al diccionario con el menor indice no
 * utilizado, escribe el código de esta palabra menos el último carácter
 * en la salida y empieza a buscar otra empezando con el ultimo carácter leído.
 * Para escribir los códigos en el fichero comprimido se puede utilizar un
 * tamaño fijo, pero para no limitar el tamaño del diccionario al número de
 * palabras que se pueden representar en este número fijo de bits se utilizan
 * tamaños variables. Se empieza con un tamaño pequeño y cuando el siguiente
 * indice no utilizado no puede ser representado en este número de bits se
 * aumenta el tamaño.
 * Para tener una búsqueda rápida se puede utilizar una variación de la
 * estructura de datos arborescente que en la literatura se conoce como Trie,
 * donde buscar una palabra e insertar una tiene coste lineal respecto a la
 * longitud de la palabra buscada/insertada.
 * Dado que el diccionario no puede crecer infinitamente grande por razones
 * de memoria, se establece un tamaño máximo del diccionario y cuando se
 * llega a este tamaño se escribe el código de la palabra acumulada, se
 * reinicia el diccionario y se sigue con la compresión.<br>
 *
 * Descompresión:
 * Para hacer la descompresión es necesario recrear el diccionario de la
 * compresión. Se inicializa el diccionario, después se lee un código y
 * se escribe la palabra correspondiente en la salida. A continuación se
 * leen todos los códigos y se descomprimen. Si el código leído está en el
 * diccionario entonces se escribe en la salida la cadena de caracteres
 * correspondiente al código leído y se añade al diccionario la cadena
 * resultante a la concatenación de la palabra correspondiente al penúltimo
 * código descomprimido y el primer carácter del la palabra actual, en otro
 * caso se añade al diccionario y se escribe en la salida la palabra
 * correspondiente a la concatenación de la palabra del penúltimo código
 * descomprimido y el primer carácter de la misma palabra. Si se utilizan
 * códigos de tamaño variable el tamaño de los códigos a leer cambian cuando
 * el tamaño del diccionario es el máximo código representable con este
 * número de bits menos uno.<br>
 *
 *
 * \subsection JPEG Algoritmo JPEG
 *
 * El algorimto JPEG és lossy, lo que significa que al comprimir se pierden
 * algunos datos. Este algoritmo se aprovecha de la dificutad de los humanos
 * para distinguir el color a muy baja escala. Empieza cambiando los pixeles
 * base de color, de RGB a YCbCr. Para poder separar entre la luminancia (Y)
 * i la crominancia(C) del pixel. Luego dividimos la imagen en bloques de 8x8
 * pixeles y creamos 3 arrays (uno para cada canal) que los contenga todos.
 * Después de esto centramos el valor en 0 (restamos 128 a cada valor del
 * bloque) para poder aplicarle la transformación discreta del coseno. Una
 * vez echo esto, dividimos los valores entre la tabla de quantización de
 * luminancia o crominancia respectivamente (estas tablas son del estandard
 * del JPEG) para conseguir más 0s. De esta forma serà más eficiente el
 * algortmo de Huffman al comprimir la foto. Ahora leo todos los bloques
 * en zig-zag para que me queden todos los 0s de cada bloque al final de una
 * cadena de enteros. Luego añado esta cadena de enteros de todos los bloques
 * y de todos los canales en un array de enteros, y se lo paso a la classe
 * Huffman que va a comprimir esta cadena utilizando el algoritmo de Huffman,
 * con el que crea un arbol de frequéncias para asignar codigos de longitud
 * variable a cada entero, teniendo los enteros que salen más un codigo más
 * corto y así aprovechar espacio. Para crear el arbol de Huffman uso una
 * clase muy sencilla llamada Node. Primero calculo las frequéncias de cada
 * entero y las guardo en un LinkedHaskMap. Luego genero una priority queue
 * que guardará los enteros por orden de frequencia. Con esto genero el arbol.
 * Después recorro de forma recursiva el arbol y al llegar a cada hoja le
 * assigno a cada entero un codigo, que guardaré en un HashMap que me sirve
 * de diccionario. Lego genero una linkedList de enteros donde cada entero
 * representa un bit. Primero guardo el diccionario en ella (en un futuro
 * guardaré el arbol en preorden) y luego voy guardando en codigo de cada
 * entero de la cadena de enteros original. Una vez echo esto convierto esta
 * cadena de bits en un array de bytes para generar el archivo comprimido.
 * Para la descompresión hago todos los pasos que he echo anteriormente en
 * orden inverso. Leo el archivo y se lo passo a la classe huffman que lo
 * decodifica utilizando el diccionario inicial. Esta me devuelve el array
 * de enteros que anteriormente codificamos. Con esta array volvemos a
 * generar todos los bloques, los multiplicamos por las tablas de
 * cuantizacion y les aplicamos la transformada inversa del coseno para
 * recuperar los valor iniciales que teniamos anteriormente. En este proceso
 * y en el proceso anterior de la DCT para comprimir es donde se pierden los
 * datos, ya que redondeamos al entero más próximo. Una vez echo esto ya
 * sumamos los 128 que anteriormente restamos y ya volvemos a tener los
 * pixeles originales. Hecho esto, solo nos falta generar la cabecera en ASCII
 * del archivo (que puedo generar ya que los primeros enteros que
 * descomprimimos con Huffman son el nivel de compressión, la anchura y la
 * altura de la foto) y pasar los enteros de cada pixel a bytes siguiendo el
 * estandard de los archivos ppm.
 *
 * \section install_sec Instalacion
 *
 * Para instalar el programa se debe ejecutar el comando:<br>
 * <br>
 * @b make <br>
 * <br>
 * Para ejecutar el programa principal se debe ejecutar el comando:<br>
 * <br>
 *      @b make @b run <br>
 * <br>
 * Para ejecutar cualquier otro Driver o Test se utiliza el compando:<br>
 * <br>
 *     @b make @b -cp @b "bin/" @b nombre_de_la_clase <br>
 * <br>
 * Para borrar todos los ejecutables se utiliza el comando>: <br>
 * <br>
 * @b make @b clean <br>
 * <br>
 */